{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"Workflow for Transparent and Robust Virus Variant Calling, Genome Reconstruction  and Lineage Assignment"},{"location":"#workflow-overview","title":"Workflow Overview","text":""},{"location":"#highlights","title":"Highlights","text":"<ul> <li> <p>Using state of the art tools, easily extended for other viruses</p> </li> <li> <p>Tool and database updates for critical components via Conda</p> </li> <li> <p>Built using modern design patterns with Conda and Snakemake</p> </li> <li> <p>Extensible and easy to customize</p> </li> <li> <p>Submission Ready Genomes</p> </li> <li> <p>Customizable reporting with comprehensive visualization</p> </li> </ul> <p></p> <p>Four different example elements of the results generated by UnCoVar:</p> <ul> <li> <p>a: The genome coverage of the aligned reads, visualized for multiple samples</p> </li> <li> <p>b: evaluation of known protein alterations from VOCs for one sample</p> </li> <li> <p>c: a pileup of reads at the position of one protein alteration. The mutations  observed for multiple reads (grey bars) for a single sample, here in the S gene</p> </li> <li> <p>d: The lineage assignments inferred for single reads for one sample</p> </li> </ul>"},{"location":"benchmarking/","title":"Benchmarking &amp; Tests","text":""},{"location":"benchmarking/#variant-call-test-cases","title":"Variant Call Test Cases","text":"<p>If you suspect that variant calls are wrong, you can create test cases and commit them to the varlociraptor team.</p> <p>To create test cases, you need to provide the same sample twice to UnCoVar: once sequenced on the Illumina platform and once sequenced on the Oxford Nanopore platform. Add a new column to the <code>config/pep/samples.csv</code> named <code>test_case</code>. Add a unique identifier to the twice sequenced sample. Here is an example:</p> sample_name fq1 fq2 date is_amplicon_data technology test_case illumina-sample PATH/TO/fq1 PATH/TO/fq2 1970-01-01 0 illumina test-case-1 nanopore-sample PATH/TO/fq 1970-01-01 1 ont test-case-1 <p>To generate the test cases, request:</p> <pre><code>snakemake --cores all --use-conda generate_test_cases\n</code></pre> <p>After finished execution, you can find the test cases in <code>results/testcases</code> directory together with a summary file.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#111-2024-11-04","title":"1.1.1 (2024-11-04)","text":""},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix file not found error on shared fs storage (#673) (c28db96)</li> </ul>"},{"location":"changelog/#110-2024-10-31","title":"1.1.0 (2024-10-31)","text":""},{"location":"changelog/#features","title":"Features","text":"<ul> <li>FLiRT Mutations column (#664) (f77d42e)</li> </ul>"},{"location":"changelog/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>changed kraken input files for ont (#650) (b62007c)</li> <li>move primer file location under workflow; this avoids file not being found in shared filesystems (#665) (9cb1576)</li> <li>pangolin data updates (#662) (f46ec83)</li> <li>replace ragoo with ragtag (#591) (e64e9db)</li> </ul>"},{"location":"changelog/#100-2024-04-17","title":"1.0.0 (2024-04-17)","text":""},{"location":"changelog/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>docs deployment (#635) (dd767b0)</li> <li>more meaningful info for patient overview table (#609) (77f7960)</li> <li>pin to varlociraptor 8.4.4 (#634) (a4e1ea8)</li> <li>pipe of stdout (#631) (a48a357)</li> <li>remove -r flag (#624) (4f1b56b)</li> <li>update link for covariants (#626) (e6476b6)</li> </ul>"},{"location":"changelog/#miscellaneous-chores","title":"Miscellaneous Chores","text":"<ul> <li>release 1.0.0 (07d6fe2)</li> </ul>"},{"location":"changelog/#0160-2023-11-16","title":"0.16.0 (2023-11-16)","text":""},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>Update README.md for dark/light theme (#614) (33ac5f7)</li> </ul>"},{"location":"changelog/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>changes in path requirements for snakedeploy (#590) (406d456)</li> <li>improved clonality event definition, usage of major subclone for assembly polishing; upgrade to varlociraptor 6.0 (#585) (aced95e)</li> <li>QA genome generation (#613) (2bb74bf)</li> <li>switch from jupyter notebook to script (#598) (d0f293d)</li> <li>update multiqc (#607) (0070d89)</li> <li>use homopolymer-pair-HMM-mode of Varlociraptor in case of nanopore reads (505a271)</li> <li>use homopolymer-pair-HMM-mode of Varlociraptor in case of nanopore reads (#587) (9bc814f)</li> </ul>"},{"location":"changelog/#performance-improvements","title":"Performance Improvements","text":"<ul> <li>update to varlociraptor 8.4 (#596) (34701af)</li> </ul>"},{"location":"changelog/#0151-2022-11-30","title":"0.15.1 (2022-11-30)","text":""},{"location":"changelog/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>ci: update black to rev 22.3.0 (#523) (2273b7d)</li> <li>disable ont actions (#555) (56e46ef)</li> <li>Replace outdated df append (#544) (4a40003)</li> <li>update channel priorities and snakemake wrappers (#562) (a0b6fd0)</li> <li>use latest varlociraptor release and ignore all biases in case of known lineage variant calling (#575) (fa957fd)</li> <li>voc probability (#541) (db6eb17)</li> </ul>"},{"location":"changelog/#0150-2022-03-24","title":"0.15.0 (2022-03-24)","text":""},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>update rbt to 0.39 (#510) (91b5ac5)</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>add nofilter flag for variant calls (#505) (381007c)</li> <li>primer clipping add up- and downstream (#515) (5c886fa)</li> </ul>"},{"location":"changelog/#0140-2022-03-21","title":"0.14.0 (2022-03-21)","text":""},{"location":"changelog/#features_3","title":"Features","text":"<ul> <li>add variant call details based on protein annotation (#487) (016bcfb)</li> <li>call known lineage variants (#392) (9ad720c)</li> <li>deps: bump github/super-linter from 4.8.6 to 4.8.7 (#459) (c18f241)</li> <li>deps: update pangolin to 3.1.19 (#461) (3971687)</li> <li>deps: update pangolin to 3.1.19 (#461) (d5f42ca)</li> <li>deps: update pangolin to 3.1.20 (#467) (78cb7f4)</li> <li>make incoming and archive structure data-handling optional (#443) (559e9c1)</li> <li>make sending lab column in rki report csv adjustable via config file (#492) (311e857)</li> <li>rule and script bed_to_bedpe (#447) (3022eab)</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>add missing fasta index to vcf report (#480) (1697fb5)</li> <li>add missing voc variant report to environmental report (#479) (16baef1)</li> <li>bump rust-bio-tools to 0.38 (#449) (e85fa15)</li> <li>canu and porechop logging (5db0935)</li> <li>canu and porechop logs (#473) (497bfcd)</li> <li>ci: add missing missing echo to release please (#476) (6a0b899)</li> <li>ci: change human reference from NC_000021.9 to BA000005.3 (#488) (14b4be0)</li> <li>ci: change release please PR branch (#481) (603d3b5)</li> <li>ci: parse new json output from release please (#474) (eb598b7)</li> <li>ci: release please checkout branch (#477) (03a69bf)</li> <li>correct filtering in plot-lineages-over-time (#445) (c71f72b)</li> <li>deps: update multiqc wrapper (#329) (42fbcd8)</li> <li>fixed include flag KeyError (#452) (f47dad2)</li> <li>order of include flag sample (#462) (429e5d9)</li> <li>pangolin plot color (#483) (9e368d5)</li> <li>reduce loading time of coverage plots (#498) (8a8f533)</li> <li>remove removal of .indicators/replacement_notice.txt for int (#457) (c5b9f6c)</li> <li>rename column header in report formatter (#444) (8ba21d9)</li> <li>reset over table formatter (#448) (ee30a46)</li> <li>untmp recalibrated bam (#491) (1118fd9)</li> <li>VOC mutation table similarity calculation (#484) (82405ee)</li> </ul>"},{"location":"changelog/#performance-improvements_1","title":"Performance Improvements","text":"<ul> <li>add ont temp flags (#475) (6447583)</li> <li>ont downsampling normalisation (#489) (f502dd2)</li> <li>optimisations for ont - barcode+adapter-trimming, primer-trimming (porechop) and read correction (Canu) (#454) (e844fc4)</li> </ul>"},{"location":"changelog/#0132-2022-01-06","title":"0.13.2 (2022-01-06)","text":""},{"location":"changelog/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>wrong enumeration with kallisto included (#439) (1a68969)</li> </ul>"},{"location":"changelog/#0131-2022-01-04","title":"0.13.1 (2022-01-04)","text":""},{"location":"changelog/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>relative aggregation sample plot (#412) (6a8155e)</li> </ul>"},{"location":"changelog/#0130-2022-01-03","title":"0.13.0 (2022-01-03)","text":""},{"location":"changelog/#features_4","title":"Features","text":"<ul> <li>add optional column for adapters (#419) (f883ce2)</li> <li>add patient or environmental mode flag (#420) (9ac2002)</li> <li>add prettier to pre-commit (#427) (e7cb0a7)</li> </ul>"},{"location":"changelog/#bug-fixes_9","title":"Bug Fixes","text":"<ul> <li>generate high quality report .csv file (#433) (077b80d)</li> </ul>"},{"location":"changelog/#0120-2021-12-23","title":"0.12.0 (2021-12-23)","text":""},{"location":"changelog/#features_5","title":"Features","text":"<ul> <li>add varlociraptor test case generation (#429) (3ec7975)</li> </ul>"},{"location":"changelog/#bug-fixes_10","title":"Bug Fixes","text":"<ul> <li>update the mutations columns in the overview table formatter (#423) (3af43b9)</li> </ul>"},{"location":"changelog/#0110-2021-12-21","title":"0.11.0 (2021-12-21)","text":""},{"location":"changelog/#features_6","title":"Features","text":"<ul> <li>update to rust-bio-tools 0.33 (#388) (8f66915)</li> <li>update to varlociraptor 4.9 (#424) (5a7ca5b)</li> </ul>"},{"location":"changelog/#0102-2021-12-19","title":"0.10.2 (2021-12-19)","text":""},{"location":"changelog/#bug-fixes_11","title":"Bug Fixes","text":"<ul> <li>pangolin input for overview table, bamclipper samtools error, include flag for high quality genome report (#418) (9690f12)</li> </ul>"},{"location":"changelog/#0101-2021-12-17","title":"0.10.1 (2021-12-17)","text":""},{"location":"changelog/#bug-fixes_12","title":"Bug Fixes","text":"<ul> <li>names in report (#410) (e5dbcbd)</li> </ul>"},{"location":"changelog/#0100-2021-12-16","title":"0.10.0 (2021-12-16)","text":""},{"location":"changelog/#features_7","title":"Features","text":"<ul> <li>complete workflow if no samples pass the quality filter (#411) (55b2dcc)</li> </ul>"},{"location":"changelog/#090-2021-12-15","title":"0.9.0 (2021-12-15)","text":""},{"location":"changelog/#features_8","title":"Features","text":"<ul> <li>added variants-over-time-plot to report again (#405) (bd5048a)</li> </ul>"},{"location":"changelog/#080-2021-12-15","title":"0.8.0 (2021-12-15)","text":""},{"location":"changelog/#features_9","title":"Features","text":"<ul> <li>add pangolin call table (#397) (953211a)</li> <li>add rki include/exclude flag (#319) (d2e6d20)</li> <li>added column in overview table for the clear name of the lineage (#400) (38e34bb)</li> </ul>"},{"location":"changelog/#bug-fixes_13","title":"Bug Fixes","text":"<ul> <li>change report structure, add masked sequence, pangolin call on polished sequence (#396) (d2ecaaa)</li> <li>rmv pipe from pre-commit (#401) (3222bb2)</li> </ul>"},{"location":"changelog/#070-2021-12-14","title":"0.7.0 (2021-12-14)","text":""},{"location":"changelog/#features_10","title":"Features","text":"<ul> <li>add pre commit checks (#398) (6982b3d)</li> </ul>"},{"location":"changelog/#bug-fixes_14","title":"Bug Fixes","text":"<ul> <li>remove cwd-check in update sample sheet script (#393) (44d49d3)</li> <li>trigger docs build on release created (#391) (e240aeb)</li> </ul>"},{"location":"changelog/#060-2021-12-13","title":"0.6.0 (2021-12-13)","text":""},{"location":"changelog/#features_11","title":"Features","text":"<ul> <li>update pangolin to 3.1.17 (#389) (23ed39e)</li> <li>update varlociraptor to version 4.8 (#331) (0096376)</li> </ul>"},{"location":"changelog/#bug-fixes_15","title":"Bug Fixes","text":"<ul> <li>generation of high quality genomes (#394) (da00975)</li> <li>relative aggregation of samples for variants and lineages over time plots (#382) (ebe556c)</li> </ul>"},{"location":"changelog/#050-2021-12-09","title":"0.5.0 (2021-12-09)","text":""},{"location":"changelog/#features_12","title":"Features","text":"<ul> <li>technology: add ion torrent processing (#383) (288777c)</li> </ul>"},{"location":"changelog/#041-2021-12-07","title":"0.4.1 (2021-12-07)","text":""},{"location":"changelog/#bug-fixes_16","title":"Bug Fixes","text":"<ul> <li>ci: adjust commit message of copyright-preamble.yml to fit conventional commits format (#369) (e067895)</li> <li>GISAID lineage extraction [B.1.1.529 (probably).fasta] (#372) (7750862)</li> </ul>"},{"location":"changelog/#040-2021-12-02","title":"0.4.0 (2021-12-02)","text":""},{"location":"changelog/#features_13","title":"Features","text":"<ul> <li>technology: add Oxford Nanopore processing (#305) (55f38f3)</li> </ul>"},{"location":"changelog/#bug-fixes_17","title":"Bug Fixes","text":"<ul> <li>add bam index for extract_reads_of_interest (#366) (5f5dd27)</li> <li>changed contigs file for quast-rule to avoid workflow to stop because of low read numbers (#338) (2d0e246)</li> <li>changed JSON schema validator and updated files #364 (75e62f2)</li> </ul>"},{"location":"changelog/#performance-improvements_2","title":"Performance Improvements","text":"<ul> <li>changed chunksize of read json file from gisaid, excluded lineage without name (#328) (b9e5c49)</li> </ul>"},{"location":"changelog/#031-2021-11-29","title":"0.3.1 (2021-11-29)","text":""},{"location":"changelog/#bug-fixes_18","title":"Bug Fixes","text":"<ul> <li>nested function usage and remove code duplication (#323) (91e3ce9)</li> </ul>"},{"location":"changelog/#030-2021-11-05","title":"0.3.0 (2021-11-05)","text":""},{"location":"changelog/#features_14","title":"Features","text":"<ul> <li>add aggregation rule for publication plots (#275) (a93bc18)</li> <li>add more voc mutations to config (#314) (5098605)</li> <li>add plot of reads needed for sufficient lineage calling (#263) (982f997)</li> <li>add plot of variants over time (#279) (66ab121)</li> <li>add schemes for sample sheet and config file (#278) (09976b3)</li> <li>add standard reference lineages for kallisto based lineage calling (#280) (6bb32f6)</li> <li>add todo action (#277) (c1e44c5)</li> <li>add workflow catalog yml (#199) (2013533)</li> <li>comparison of assemblers (#172) (8233829)</li> </ul>"},{"location":"changelog/#bug-fixes_19","title":"Bug Fixes","text":"<ul> <li>add \"snakemake\" in the readme for the Snakemake Workflow Catalog requirements (#309) (2e5212c)</li> <li>changed call config file in update-sample-sheet (#307) (406aef7)</li> <li>shotgun typo in config.yaml  (#308) (d30f02b)</li> <li>specify snakemake version used in pangolin env (#284) (79a12a8)</li> </ul>"},{"location":"changelog/#025-2021-09-23","title":"0.2.5 (2021-09-23)","text":""},{"location":"changelog/#bug-fixes_20","title":"Bug Fixes","text":"<ul> <li>sha tag name (#273) (b6d1265)</li> </ul>"},{"location":"changelog/#024-2021-09-23","title":"0.2.4 (2021-09-23)","text":""},{"location":"changelog/#bug-fixes_21","title":"Bug Fixes","text":"<ul> <li>add log in to quay registry (#271) (16080de)</li> </ul>"},{"location":"changelog/#023-2021-09-23","title":"0.2.3 (2021-09-23)","text":""},{"location":"changelog/#bug-fixes_22","title":"Bug Fixes","text":"<ul> <li>update readme to trigger release (#269) (19129a9)</li> </ul>"},{"location":"changelog/#022-2021-09-22","title":"0.2.2 (2021-09-22)","text":""},{"location":"changelog/#bug-fixes_23","title":"Bug Fixes","text":"<ul> <li>rmv path for buildah (#265) (2341a61)</li> </ul>"},{"location":"changelog/#021-2021-09-22","title":"0.2.1 (2021-09-22)","text":""},{"location":"changelog/#bug-fixes_24","title":"Bug Fixes","text":"<ul> <li>container version tag (#262) (d4c1ef6)</li> </ul>"},{"location":"changelog/#020-2021-09-22","title":"0.2.0 (2021-09-22)","text":""},{"location":"changelog/#features_15","title":"Features","text":"<ul> <li>adding new rule update_sample to workflow (#254) (3878c1b)</li> </ul>"},{"location":"changelog/#bug-fixes_25","title":"Bug Fixes","text":"<ul> <li>maximize build space for container image (#261) (0de2cc9)</li> </ul>"},{"location":"changelog/#018-2021-09-20","title":"0.1.8 (2021-09-20)","text":""},{"location":"changelog/#bug-fixes_26","title":"Bug Fixes","text":"<ul> <li>add missing path to the Dockerfile job (#258) (e733d2d)</li> </ul>"},{"location":"changelog/#017-2021-09-20","title":"0.1.7 (2021-09-20)","text":""},{"location":"changelog/#bug-fixes_27","title":"Bug Fixes","text":"<ul> <li>update snakemake actions for container file (#256) (cb31e92)</li> </ul>"},{"location":"changelog/#016-2021-09-16","title":"0.1.6 (2021-09-16)","text":""},{"location":"changelog/#bug-fixes_28","title":"Bug Fixes","text":"<ul> <li>change path of docker file (#251) (1abebcf)</li> </ul>"},{"location":"changelog/#015-2021-09-15","title":"0.1.5 (2021-09-15)","text":""},{"location":"changelog/#bug-fixes_29","title":"Bug Fixes","text":"<ul> <li>add GISAID var to env (#248) (e859aed)</li> </ul>"},{"location":"changelog/#014-2021-09-14","title":"0.1.4 (2021-09-14)","text":""},{"location":"changelog/#bug-fixes_30","title":"Bug Fixes","text":"<ul> <li>change \" to ' (#246) (ffca497)</li> </ul>"},{"location":"changelog/#013-2021-09-09","title":"0.1.3 (2021-09-09)","text":""},{"location":"changelog/#bug-fixes_31","title":"Bug Fixes","text":"<ul> <li>add extract gisaid env (#235) (2b94752)</li> <li>improve if statement with release check (#239) (12cc85f)</li> </ul>"},{"location":"changelog/#012-2021-09-06","title":"0.1.2 (2021-09-06)","text":""},{"location":"changelog/#bug-fixes_32","title":"Bug Fixes","text":"<ul> <li>merge push to quay.io into release please (#231) (e9d782d)</li> <li>remove pre von relase action (#232) (301043f)</li> </ul>"},{"location":"changelog/#011-2021-09-01","title":"0.1.1 (2021-09-01)","text":""},{"location":"changelog/#bug-fixes_33","title":"Bug Fixes","text":"<ul> <li>change trigger of registry release action (#223) (1464ece)</li> </ul>"},{"location":"changelog/#010-2021-08-31","title":"0.1.0 (2021-08-31)","text":""},{"location":"changelog/#bug-fixes_34","title":"Bug Fixes","text":"<ul> <li>change release-please-action (#217) (20af1db)</li> <li>change trigger of release please (#212) (c7a9978)</li> <li>relase plase indent (#216) (9140a29)</li> <li>release command (#219) (fb84404)</li> <li>release please command (#218) (7c64689)</li> <li>release please if statement (#220) (41f41d5)</li> <li>release please local PR checkout (#221) (b348aa7)</li> <li>release please pr tag (#215) (5d54bb4)</li> <li>release please rmv double dollar (#222) (0003da9)</li> <li>release please step id (#214) (fa5a9cc)</li> </ul>"},{"location":"changelog/#miscellaneous-chores_1","title":"Miscellaneous Chores","text":"<ul> <li>release 0.1.0 (#201) (f211058)</li> </ul>"},{"location":"configuration/","title":"Advanced Configuration","text":"<p>The config file, found under <code>config/config.yaml</code> can be used to adapt your analysis.</p>"},{"location":"configuration/#execution-mode","title":"Execution Mode","text":"<pre><code># execution mode. Can be either \"patient\" or \"environment\"\nmode: environment\n</code></pre> <p>Defines the execution mode of UnCoVar.</p> <p>When the mode is set to <code>patient</code>, the sample is assumed come be from a single host organism and contains only one strain of SARS-CoV-2. The parts of the workflow for reconstructing the SARS-CoV-2 strain genome are activated.</p> <p>If the mode is set to <code>environment</code>, the sample is assumed to be from the environment (e.g. wastewater) and to contain different SARS-CoV-2 strains. The parts of the workflow responsible for creating and analysing individual genomes (e.g. assembly, lineage calling via Pangolin) are disabled.</p>"},{"location":"configuration/#sending-lab-number","title":"Sending lab number","text":"<p>UnCoVar automatically generates a multi-Fasta file and a corresponding <code>.csv</code> for  all samples with a <code>1</code> flag for <code>inlcude_in_high_genome_summary</code> in the sample sheet,  that match the given <code>quality-criteria</code> (see below). The reporting format and the  quality criteria are inspired by the requirements for SARS-CoV-2 genome submission  to the Robert-Koch-Institute, Germany.  The sending lab number will be included in the <code>.csv</code> file</p>"},{"location":"configuration/#data-handling","title":"Data handling","text":"<p>With the root of the UnCoVar workflow as working directory, we recommended to  use the following folder structure:</p> <pre><code>\u251c\u2500\u2500 archive\n\u251c\u2500\u2500 incoming\n\u2514\u2500\u2500 uncovar\n    \u2514\u2500\u2500 data\n        \u2514\u2500\u2500 2023-12-24\n</code></pre> <p>The structure can be adjusted to via the config under <code>data-handling</code>:</p> <pre><code>data-handling:\n  # flag for using the following data-handling structure\n  # True: data-handling structure is used as shown below\n  # False: only the sample sheet needs to be updated (manually)\n  use-data-handling: True\n  # flag for archiving data\n  # True: data is archived in path defined below\n  # False: data is not archived\n  archive-data: False\n  # path of incoming data, which is moved to the\n  # data directory by the preprocessing script\n  incoming: ../incoming/\n  # path to store data within the workflow\n  data: data/\n  # path to archive data from incoming and\n  # the results from the latest run to\n  archive: ../archive/\n</code></pre>"},{"location":"configuration/#quality-criteria","title":"Quality criteria","text":"<p>The quality criteria can be adjusted to your individual needs. By default they match  the quality criteria needed for submitting to the RKI (see Sending lab number  above)</p> <pre><code>quality-criteria:\n  illumina:\n    # minimal length of acceptable reads\n    min-length-reads: 30\n    # average quality of acceptable reads (PHRED)\n    min-PHRED: 20\n  ont:\n    # minimal length of acceptable reads\n    min-length-reads: 200\n    # average quality of acceptable reads (PHRED)\n    min-PHRED: 10\n  # identity to virus reference genome (see-above) of reconstructed sequence\n  min-identity: 0.9\n  # share N in the reconstructed sequence\n  max-n: 0.05\n  # minimum local sequencing depth without filtering of PCR duplicates\n  min-depth-with-PCR-duplicates: 20\n  # minimum local sequencing depth after filtering PCR duplicates\n  min-depth-without-PCR-duplicates: 10\n  # minimum informative allele frequency\n  min-allele: 0.9\n</code></pre>"},{"location":"configuration/#preprocessing","title":"Preprocessing","text":"<p>Here different preprocessing can be adjustet. Per default the standard Illumina adapters  are trimmed. For samples prepared with an amplicon sequencing approach, you can  define the path to the primer file in <code>.bed</code> format. If you are processing Nanopore  samples, you can also define the primer version via changing the number.</p> <p>The default primer file is a bed file from the ARTIC network. However, the primers for clipping can be customized. First, the custom primers must be saved in bed format. Next, the path to this file must be changed in the config. Go to the config folder and open config.yaml. In the \"preprocessing\" subcategory, change the path after \"amplicon-primers\" to the path where your primer file can be found.</p> <pre><code>preprocessing:\n  # only for *non* Oxford Nanopore data. Adapters to trim.\n  # see: https://www.nimagen.com/shop/products/rc-cov096/easyseq-sars-cov-2-novel-coronavirus-whole-genome-sequencing-kit\n  kit-adapters: \"--adapter_sequence GCGAATTTCGACGATCGTTGCATTAACTCGCGAA --adapter_sequence_r2 AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"\n  # only for Oxford Nanopore data.\n  # ARTIC primer version to clip from reads. See\n  # https://github.com/artic-network/artic-ncov2019/tree/master/primer_schemes/nCoV-2019/V4\n  # for more information\n  artic-primer-version: 4\n  # path to amplicon primers in bed format for hard-clipping on paired end files (illumina) or url to file that should be downloaded\n  amplicon-primers: \"resources/SARS-CoV-2-artic-v4_1.primer.bed\"\n  # GenBank accession of reference sequence of the amplicon primers\n  amplicon-reference: \"MN908947\"\n</code></pre>"},{"location":"configuration/#assembly","title":"Assembly","text":"<p>In this section you define which assembler you want to use for the genome reconstruction.  UnCoVar uses MEGAHIT and metaSPAdes by default, as those achieved the best results  in a benchmarking comparison. The assembly options can be changed independently.</p> <p>There are several other options available:</p> <ul> <li>megahit-std</li> <li>megahit-meta-large</li> <li>megahit-meta-sensitive</li> <li>trinity</li> <li>velvet</li> <li>metaspades</li> <li>coronaspades</li> <li>spades</li> <li>rnaviralspades</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Here you will find all the information and steps necessary to contribute to UnCoVar.</p>"},{"location":"contributing/#snakemake","title":"Snakemake","text":"<p>We use <code>snakemake</code> as the backbone of this project. Have a look at the official documentation.</p> <p>If you already have <code>conda</code> installed, run:</p> <pre><code>conda create -c conda-forge -c bioconda -n snakemake snakemake\n</code></pre> <p>For faster installation, you can use <code>mamba</code>, a reimplementation of the conda package manager in C++.</p> <pre><code>mamba create -c conda-forge -c bioconda -n snakemake snakemake\n</code></pre> <p>Once installed, activate your <code>snakemake</code> environment by running</p> <p><code>conda activate snakemake</code>.</p>"},{"location":"contributing/#pre-commit","title":"Pre-Commit","text":"<p>Git hook scripts help identify simple issues before submission to code review. We run our hooks on every commit to automatically point out problems in code such as missing semicolons, trailing whitespace, and debug statements. Pointing these issues out before code review allows a code reviewer to focus on the architecture of a change while not wasting time with trivial style nitpicks.</p> <p>Before you can run hooks, you need to have the <code>pre-commit</code> package manager installed.</p> <p>Using pip:</p> <pre><code>pip install pre-commit\n</code></pre> <p>Using homebrew:</p> <pre><code>brew install pre-commit\n</code></pre> <p>Using conda (via conda-forge):</p> <pre><code>conda install -c conda-forge pre-commit\n</code></pre> <p>Finally, set up the git hook scripts:</p> <pre><code>pre-commit install\n</code></pre> <p>Now, <code>pre-commit</code> will run automatically on <code>git commit</code>. If you want to manually run all pre-commit hooks on a repository, run</p> <pre><code>pre-commit run --all-files\n</code></pre> <p>To run individual hooks use <code>pre-commit run &lt;hook_id&gt;</code>.</p>"},{"location":"contributing/#get-a-copy-of-the-workflow","title":"Get a Copy of the Workflow","text":"<p>Follow the following steps to acquire a local copy of UnCoVar:</p> <ol> <li>Fork the original repo    to a personal or lab account.</li> <li>Clone the    fork to your local system (to a different place than where you would run analysis).</li> <li>Implement your changes.</li> </ol>"},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<p>Before submitting your code, please do the following:</p> <ol> <li>Add tests, if possible, for the new changes.</li> <li>Edit documentation if you have changed something significant.</li> <li>Make sure the <code>pre-commit</code>    hooks had run (e.g. by <code>precommit run --all</code>).</li> <li>Commitand push    your changes to your fork.</li> <li>Create a pull request    against the original repository.</li> </ol>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Test cases are in the subfolder <code>.tests</code>. They are automatically executed via continuous integration with Github Actions.</p>"},{"location":"contributing/#other-help","title":"Other Help","text":"<p>You can contribute by spreading the word about this project. Writing a short article on using this project would also be a considerable contribution. You can also share your best practices with us.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#install-snakemake-and-snakedeploy","title":"Install Snakemake and Snakedeploy","text":"<p>Snakemake and Snakedeploy are best installed via the Mamba package manager  (a drop-in replacement for conda). If you have neither Conda nor Mamba, it can   be installed via Mambaforge.   For other options see here.</p> <p>Given that Mamba is installed, run</p> <pre><code>    mamba create -c conda-forge -c bioconda --name snakemake snakemake snakedeploy\n</code></pre> <p>to install both Snakemake and Snakedeploy in an isolated environment. For all  following commands ensure that this environment is activated via</p> <pre><code>    conda activate snakemake\n</code></pre>"},{"location":"installation/#clone-or-deploy-workflow","title":"Clone or deploy workflow","text":"<p>First, create an appropriate project working directory on your system and enter it:</p> <pre><code>    WORKDIR=path/to/project-workdir\n    mkdir -p ${WORKDIR}\n    cd ${WORKDIR}\n</code></pre> <p>In all following steps, we will assume that you are inside of that directory.</p> <p>Given that Snakemake is installed and you want to clone the full workflow you can  do it as follows:</p> <pre><code>    git clone https://github.com/IKIM-Essen/uncovar\n</code></pre> <p>Given that Snakemake and Snakedeploy are installed and available (see Step 1),  the workflow can be deployed as follows:</p> <pre><code>    snakedeploy deploy-workflow https://github.com/IKIM-Essen/uncovar . --tag v0.16.0\n</code></pre> <p>Snakedeploy will create two folders <code>workflow</code> and <code>config</code>. The former contains  the deployment of the UnCoVar workflow as a   Snakemake module,   the latter contains configuration files which will be modified in the next step   in order to configure the workflow to your needs. Later, when executing the workflow,   Snakemake will automatically find the main Snakefile in the workflow subfolder.</p>"},{"location":"installation/#sample-and-workflow-preparation","title":"Sample and workflow preparation","text":"<p>UnCoVar is now ready to be used and will download all neccesary resources automatically.  To start your first analysis, you will need input files in FASTQ-format, that are  defined in the sample sheet in: <code>config/pep/samples.csv</code>. If you are using  read files generated with an amplicon protocol, you will also need to provide  the amplicon primer coordinates in <code>BED</code> format, so the primers are trimmed appropriately.</p> <p>With the root of the UnCoVar workflow as working directory, we recommended to  use the following folder structure:</p> <pre><code>    \u251c\u2500\u2500 archive\n    \u251c\u2500\u2500 incoming\n    \u2514\u2500\u2500 uncovar\n        \u2514\u2500\u2500 data\n            \u2514\u2500\u2500 2023-12-24\n</code></pre> <p>The structure can be adjusted via the config file: <code>config/config.yaml</code> under  <code>data-handling</code>:</p> <ul> <li>incoming: path of incoming data, which is moved to the data directory by   the preprocessing script. Defaults to <code>../incoming/</code>.</li> <li>data: path to store data within the workflow. defaults to <code>data/</code>. It is  recommend using subfolders named properly (e.g. with date)</li> <li>archive: path to archive data from the results from the analysis to.   Defaults to <code>../archive/</code>.</li> </ul>"},{"location":"installation/#sample-sheet","title":"Sample sheet","text":"<p>The sample sheet contains all samples to be analyzed by UnCoVar. UnCoVar offers  the possibility to automatically append paired-end sequenced  samples to the sample sheet. Single-end sequenced samples have to be added manually  (see Manual filling below).</p>"},{"location":"installation/#auto-filling","title":"Auto filling","text":"<p>To UnCoVars automated sample sheet filling, place your raw and compressed  FASTQ-files into the <code>../incoming</code> folder and run:</p> <pre><code>    snakemake --cores all --use-conda update_sample\n</code></pre> <p>The files are appended to the sample sheet (auto check for duplications) and are  moved into a new folder with the current date (<code>YYYY-MM-DD</code>). <code>sample_name</code>  is extracted from each filename and all characters before the first _ are used.  Make sure to include the correct flags for amplicon-generated files  (<code>is_amplicon_data</code>) and sequencing technology (<code>technology</code>). For details on  the flags for each field see below.</p>"},{"location":"installation/#manual-filling","title":"Manual filling","text":"<p>Of course, samples to be analyzed can also be added manually to the sample sheet.  For each sample a new line in <code>config/pep/samples.csv</code> with the following  information has to be defined:</p> sample_name fq1 fq2 date is_amplicon_data technology include_in_high_genome_summary example-1 PATH/TO/fq1 PATH/TO/fq2 2024-01-01 1 illumina 1 example-2 PATH/TO/fq 2024-01-01 1 ont 1 <ul> <li>sample_name: name or identifier of sample</li> <li>fq1: path to read 1 in compressed FASTQ format</li> <li>fq2: path to read 2 in conpressed FASTQ format (if paired-end sequencing)</li> <li>date: sampling date of the sample</li> <li>is_amplicon_data: indicates whether the data was generated with a   shotgun (0) or amplicon (1) sequencing</li> <li>technology: indicates the sequencing technology used to generate   the samples (illumina, ont, ion)</li> <li>include_in_high_genome_summary: indicates if sample should be included in  the submission files (1) or not (0)</li> </ul>"},{"location":"installation/#run-the-workflow","title":"Run the workflow","text":"<p>Given that the workflow has been properly deployed and configured, run Snakemake  with:</p> <pre><code>    snakemake --cores all --use-conda\n</code></pre> <p>Snakemake will automatically detect the main Snakefile in the workflow subfolder  and execute the workflow module that has been defined by the deployment.</p> <p>This workflow is written with Snakemake and details and tools are described in the Snakemake Workflow Catalog.</p> <p>If you use this workflow in your work, don't forget to give credits to the authors by citing the URL of this repository and its DOI (see above).</p>"},{"location":"installation/#general-settings","title":"General settings","text":""},{"location":"installation/#config-file","title":"Config file","text":"<p>To configure this workflow, modify <code>config/config.yaml</code> according to your  needs, following the explanations provided in the file. It is especially recommended  to provide a <code>BED</code> file with primer coordinates, when the analyzed reads derive  from amplicon-tiled sequencing, so the primers are trimmed appropriately.</p> <p>The incoming directory should contain paired end reads in (compressed) FASTQ format. UnCoVar automatically copies your data into the data directory and moves all files from incoming directory to the archive. After the analysis, all results are compressed and saved alongside the reads.</p>"},{"location":"license/","title":"License","text":"<p>BSD 2-Clause License</p> <p>Copyright (c) 2020, Thomas Battenfeld, Johannes K\u00f6ster, Folker Meyer, Alexander Thomas All rights reserved.</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"tools/","title":"About","text":""},{"location":"tools/#the-team","title":"The team","text":"<ul> <li>Alexander Thomas</li> <li>Thomas Battenfeld</li> <li>Simon Magin</li> <li>Johannes Koester</li> <li>Folker Meyer</li> </ul>"},{"location":"tools/#tools-used-in-uncovar","title":"Tools used in UnCoVar","text":"Stage Step Tool Illumina Tool Nanopore SARS-CoV-2 specific Preprocessing primer clipping BAMClipper NoTrAmp no quality clipping fastp fastp no contamination removal Kraken2 Kraken2 no denoising - Canu, Medaka no Assembly assembly MEGAHIT, metaSPAdes MEGAHIT, metaSPAdes no scaffolding RaGOO RaGOO no Analysis SNV calling freeBayes, DELLY Medaka variant, Longshot no SNV validation Varlociraptor Varlociraptor no Lineage call read based lineage assignment Kallisto Kallisto no lineage call Pangolin Pangolin yes <p>This project wouldn't be possible without several open source tools and libraries:</p> <p>Altair</p> <p>BCFtools</p> <p>BEDTools</p> <p>Biopython</p> <p>bwa</p> <p>Covariants</p> <p>delly</p> <p>ensembl-vep</p> <p>entrez-direct</p> <p>FastQC</p> <p>fgbio</p> <p>FreeBayes</p> <p>intervaltree</p> <p>Jupyter</p> <p>kallisto</p> <p>Krona</p> <p>mason</p> <p>MEGAHIT</p> <p>Minimap2</p> <p>MultiQC</p> <p>pandas</p> <p>Picard</p> <p>PySAM</p> <p>QUAST</p> <p>RaGOO</p> <p>ruamel.yaml</p> <p>Rust-Bio-Tools</p> <p>SAMtools</p> <p>Snakemake</p> <p>sourmash</p> <p>SPAdes</p> <p>SVN</p> <p>Tabix</p> <p>Trinity</p> <p>Varlociraptor</p> <p>Vega-Lite</p> <p>Velvet</p> <p>vembrane</p>"},{"location":"user-guide/","title":"The Report","text":"<p>UnCoVar automatically generates a HTML-based report for a detailed insight into the analysed patient or environmental samples.</p>"},{"location":"user-guide/#section-1-overview","title":"Section 1: Overview","text":""},{"location":"user-guide/#report","title":"Report","text":"<p>An overview table of key information through several stages of the workflow. The table consists of the following columns:</p> <ul> <li>Sample: The sample name as entered in the sample sheet   (<code>config/pep/samples.csv</code>) before starting the workflow.</li> <li>Eukaryota to Unclassified: Classification of the sample contents on the   domain level. Especially interesting for samples created via   shotgun sequencing.   with amplicon tiled preparation)</li> <li>Raw Reads: Number of reads in the raw input of the sample.</li> <li>Trimmed Read: Number of reads after adapter removal.</li> <li>Filtered Reads: Number of reads after removing sequences that could belong   to the human host from which the sample was taken.</li> <li>Largest Contig: The length of the largest sequences after   de novo assembly</li> <li>De Novo Sequence: The length of the de novo assembled sequence after   reference guided scaffolding. This sequence has less bias towards the   SARS-CoV-2 reference genome.   RaGOO</li> <li>Pseudo Sequence: The length of the pseudo assembled sequence. This sequence   has a stronger bias towards the SARS-CoV-2 reference genome, as detected   variants (on read level) are applied onto that reference. Only applicable   for samples process on Illumina devices.</li> <li>Consensus Sequence: The length of the consensus sequences. This sequence   also has a bias towards the SARS-CoV-2 reference genomes. It is created by   using neural networks applied on a pileup of individual sequencing reads   against the reference genome Only applicable for samples process on   Oxford Nanopore devices.   called variants with Varlociraptor   into the Wuhan-Hu-1 Reference   <code>NC_045512.2</code></li> <li>Best Quality: Indicates which of the assemblies performed produces the   highest quality sequence and also indicates failed QC.</li> <li>Pango Lineage: Called lineage in Pango nomenclature.</li> <li>WHO Label: Lineage name determined by the WHO.</li> <li>VOC Mutations: Mutations that occur in Variants of Concern (VOC). These VOCs   typically have: Increase in transmissibility or detrimental change in COVID-19   epidemiology; OR Increase in virulence or change in clinical disease   presentation; OR Decrease in effectiveness of public health and social   measures or available diagnostics, vaccines, therapeutics.   Other Mutations: Other Mutations that occur in the sample.   of specific concern   (VOC) and other found variants</li> </ul>"},{"location":"user-guide/#section-2-variant-call-details","title":"Section 2: Variant Call Details","text":""},{"location":"user-guide/#voc-similarity","title":"VOC Similarity","text":"<p>Estimation of VOC similarity based on each sample's SNV profile, compared to all  VOCs from covariants.org.</p> <ul> <li>Mutations: All possible SNVs found in the catalog with all SNVs of the most similar   VOC showing first.</li> <li>Probability: A-posteriori probability that the observation of the mutation is true.</li> <li>Frequency: Variant allele frequency (VAF). The percentage of sequencing reads   matching a specific SNV divided by the overall coverage at   that position.</li> <li>The colmuns with the VOC names represent the Top 10 similar VOCs, based on the   similarity of their SNV profile to the SNVs found in the sample.   measure of similarity. To determine the degree of similarity between the sample   and the VOCs, we performed the following scoring. Let \\(n\\) be the total number   of variants and \\(m\\) be the number of VOCs. Let \\(X\\) be a binary matrix that   relates variants with VOCs, namely, \\(X_{i,j} = 1\\) if and only if variant \\(i\\)   is in  \\(VOC_j\\), with \\(i = 1,\\ldots,n\\) and \\(j = 1,\\ldots,m\\). Let \\(\\theta_i\\)   be the latent allele frequency of variant \\(i\\) in the given sample and \\(\\hat\\theta_i\\)   be the maximum a posteriori estimate of \\(\\theta_i\\) as provided by Varlociraptor.   Let \\(p_i = Pr(\\theta_i &gt; 0 \\mid D)\\) be the posterior probability that the variant   \\(i\\) is present in the sample (i.e., the probability that its latent allele   frequency is greater than zero, given the data \\(D\\)). Then, the similarity of   a given sample to \\(VOC_j\\) can be calculated as the Jaccard-like similarity score:</li> </ul> \\[\\frac{\\sum_{i=1}^n p_i \\cdot \\hat\\theta_i \\cdot X_{i,j} + (1-p_i) \\cdot  (1-X_{i,j})}{n}\\]"},{"location":"user-guide/#rendered-variant-callings","title":"Rendered variant callings","text":"<p>Variant callings rendered with Oncoprint:</p> <ul> <li>with high and moderate/low impact</li> <li>on ORF/Protein level</li> </ul> <p>Variant candidates are identified and called with Varlociraptor</p>"},{"location":"user-guide/#section-3-sequencing-details","title":"Section 3: Sequencing Details","text":""},{"location":"user-guide/#multiqc-report-for-overall-quality-control","title":"MultiQC report for overall quality control","text":"<ul> <li>General Stats</li> <li>Sequence Counts</li> <li>Sequence Quality Histograms</li> <li>Per Sequence Quality Scores</li> <li>Per Base Sequence Content</li> <li>Per Sequence GC Content</li> <li>Per Base N Content</li> <li>Sequence Length Distribution</li> <li>Sequence Duplication Levels</li> <li>Overrepresented sequences by samples</li> <li>Top overrepresented sequences</li> <li>Adapter Content</li> <li>Status Checks</li> <li>Software Versions</li> </ul>"},{"location":"user-guide/#coverage-of-reference-genome","title":"Coverage of Reference Genome","text":"<p>Plot that is showing how well the reference genome is covered by the reads of each  analyzed sample visualizing the depth (DP) values from SAMtools depth.</p>"},{"location":"user-guide/#section-4-sequences","title":"Section 4: Sequences","text":""},{"location":"user-guide/#quality-overview","title":"Quality Overview","text":""},{"location":"user-guide/#filter-overview","title":"Filter Overview","text":"<p>A table comparing identity and number of N bases for all samples for the reconstructed  genomes UnCoVar generates with its two main assembly methods (de novo  assembly + scaffolding and consensus sequence based on called variants).</p>"},{"location":"user-guide/#pangolin-call-overview","title":"Pangolin Call Overview","text":"<p>A table of lineage calls for all samples throughout several stages of the  workflow, as determined by Pangolin.</p> <p>These stages are:</p> <ul> <li>Scaffolded Sequences: Contigs from the   de novo assembly,   ordered against the virus reference genome (default: Wuhan-Hu-1 Reference   <code>NC_045512.2</code>) with   RaGOO.</li> <li>Polished Sequences: Scaffolded sequence polished by applying variants with   an allele frequency of 100% (called by Varlociraptor   at FDR <code>5%</code> by default).</li> <li>Masked Polished Sequences: Polished Sequences masked due to two criteria.   See below for a more in-depth explanation of these two criteria.</li> <li>Consensus Sequences: Using corrected reads and the virus reference   genome (default: Wuhan-Hu-1 Reference   <code>NC_045512.2</code>) a   consensus sequence   is generated using medaka.   Consensus Sequences are only generated for Oxford Nanopore data.</li> <li>Masked Consensus Sequences: Consensus Sequence masked due to low position   coverage. See below for a more in-depth explanation of   the criteria. Masked consensus Sequences are only generated for Oxford   Nanopore data.</li> <li>Pseudo Sequences: Sequences that are1 generated based on the virus reference   genome (default: Wuhan-Hu-1 Reference   <code>NC_045512.2</code>) and by applying   variants with an allele frequency of 100% (called by   Varlociraptor with a default FDR of <code>5%</code>).   Masked Pseudo Sequences are not generated, as the quality criteria below   are implicit considered when creating a \"normal\" Pseudo Sequence. Pseudo sequences   are only generated for Illumina and Ion Torrent data.</li> </ul>"},{"location":"user-guide/#quality-criteria","title":"Quality Criteria","text":"<ol> <li>Positions in the reconstructed genome that are covered by less than a certain    amount (default: <code>20</code>) reads are be masked with N.</li> <li>Informative positions (A, T, G, C) which are not supported by a certain    percentage (default: <code>90%</code>) of the aligned reads are masked by non-informative    placeholders of the IUPAC nucleotide code.    Not applicable for model-based basecall procedures (e.g. Oxford Nanopore).</li> </ol>"},{"location":"user-guide/#section-5-variant-call-files","title":"Section 5: Variant Call Files","text":"<p>Downloadable <code>.vcf</code> files of the different stages for variant calling:</p> <ul> <li>with high and moderate/low impact</li> <li>on ORF/Protein level</li> </ul>"},{"location":"user-guide/#section-6-high-quality-genomes","title":"Section 6: High-Quality Genomes","text":"<ul> <li>Multi-FASTA file, including the reconstructed genomes from samples, that passed   the quality control</li> <li><code>.csv</code> file, including additional submission data for each sample that passed   the quality control</li> </ul>"}]}